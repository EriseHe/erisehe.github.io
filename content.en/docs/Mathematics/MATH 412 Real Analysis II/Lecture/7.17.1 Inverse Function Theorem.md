---
title: 7.1 Inverse Function Theorem
weight: 1
---

# 7.1 Inverse Function Theorem (IFT)

Two lines of ideas:

**A**: CMP $⇒$ Inverse FT $⇒$ Applications in ODE  
**B**: IFT $⇒$ Implicit FT $⇒$ Local behavior, extreme problems  

## I. Inverse Function Theorem
### 1. Linear Case

Consider a linear map, $y = f(x): \mathbb{R}^n \to \mathbb{R}^n$.

$$
x = (x_1, x_2, \dots, x_n)^T
$$

Given $y \in \mathbb{R}^n$, $f(x)$ is a linear system of equations:

$$\begin{aligned}
y_1 &= a_{11} x_1 + a_{12} x_2 + \dots + a_{1n} x_n \\\\
y_2 &= a_{21} x_1 + a_{22} x_2 + \dots + a_{2n} x_n \\\\
&\vdots \\\\
y_n &= a_{n1} x_1 + \dots + a_{nn} x_n
\end{aligned}$$


or 
$$
A_{n\times n}X_{n\times 1} = Y_{n\times 1}
$$

> [!assumption|*]
>  $$X \text{ has a unique solution} \Longleftrightarrow \det(A) \neq 0.$$

In this case, the solution is given by:
$$
X = A^{-1} Y
$$
Thus, the inverse function satisfies:
$$
f^{-1} \circ f = \text{Identity}
$$
**The inverse theorem for $y = f(x)$:**

$$
f(f^{-1}(y)) = A A^{-1} y = y
$$

---

#### Question: When can we solve a **nonlinear** system?

We consider a system of nonlinear equations:
$$
\begin{cases}
    f_1(x_1, x_2, \dots, x_n) = y_1 \\\\
    f_2(x_1, x_2, \dots, x_n) = y_2 \\\\
    \quad \vdots \\\\
    f_n(x_1, x_2, \dots, x_n) = y_n
\end{cases}
$$
or equivalently, 
$$
f(x) = y
$$
### 2. The Inverse of a General Function

**Notation:**  
Let $y = f(x): A \subset \mathbb{R}^n \to \mathbb{R}^n$ be a **diffeomorphism**.

$$
y = (y_1, y_2, \dots, y_n)
$$

where

$$
y_i = f_i(x_1, x_2, \dots, x_n)
$$

The Jacobian determinant of $f$ at $x$ is:

$$
\det \left( \frac{\partial f_i}{\partial x_j} \right)
$$

> [!theorem|7.1.1]
>Let $y = f(x): A \subset \mathbb{R}^n \to \mathbb{R}^n$ be of class $C^1$. Suppose $x_0 \in A$ and $\det(Df(x_0)) \neq 0$. Then there exists a neighborhood $U$ of $x_0$ and a neighborhood $W$ of $y_0 = f(x_0)$ such that:
>
>1. $f: U \to W$ has an **inverse** $f^{-1}: W \to U$.
>2. $f^{-1}$ is of class $C^1$.
>3. $D(f^{-1}(y)) = (Df(x))^{-1}$ for all $y \in W$ at $y = f(x)$.

---

### Visualization:

- $y = f(x)$ maps from $U$ to $W$.
- $x = f^{-1}(y)$ gives the inverse mapping from $W$ back to $U$.
### Recall: Contraction Mapping Principle (CMP)

Let $\mathbb{X}$ be a **complete metric space** and let 

$$
\varphi: \mathbb{X} \to \mathbb{X}
$$ 

be a function satisfying a contraction condition for some constant $k$ with $0 < k < 1$:

$$
d(\varphi(x), \varphi(y)) \leq k \cdot d(x,y), \quad \forall x,y \in \mathbb{X}.
$$

Then, there exists a **unique fixed point** $X^*$ such that:

$$
\varphi(X^*) = X^*.
$$

---

## Proof of the Inverse Function Theorem (IFT)

### Step 1: Reductions

(a) **May assume** that the Jacobian matrix at $x_0$ is the identity:
$$
D f(x_0) = I.
$$
In fact, define the transformation:
$$
T = D f(x_0).
$$
Then, we can consider a new function:

$$
\tilde{f} = T^{-1} \circ f.
$$

Thus, 

$$
D(\tilde{f})(x_0) = I.
$$

(b) **Main assumption:**  

$$
x_0 = f^{-1}(y_0).
$$

To see this, define:

$$
h(x) = f(x) - f(x_0).
$$

Then,

$$
D h(x_0) = D f(x_0) - D f(x_0) = 0.
$$

If $h^{-1}$ exists, then $y = f(x)$ can be solved as:

$$
f(x) = h(x) + f(x_0) = y.
$$

Thus, the inverse function satisfies:

$$
x = x_0 - h^{-1}(y - f(x_0)).
$$

---

## Step 2: Existence of the Inverse Function

(a) **Setup:** By the reduction above, we assume:

$$
x_0 = 0, \quad y_0 = f(x_0) = 0, \quad D f(x_0) = I.
$$

**Need to show:**  
There exist neighborhoods $U$ and $W$ such that the mapping:

$$
y = f(x): U \to W
$$

has an **inverse function** in $W$, meaning:

$$
\forall y \in W, \quad \exists! x \in U \text{ such that } y = f(x).
$$

**Illustration:**  

A diagram representing $U$ mapping to $W$ via $f$, where $f$ is invertible.

---

### For a fixed $y \in \mathbb{R}^n$, define:

$$
g_x = g(y) = y + x - f(x).
$$

We need to show that **$g_x$ has a unique fixed point**.

(b) **Construction of neighborhoods $U$ and $W$**  

Let:

$$
g(x) = x - f(x).
$$

Then:

$$
D g(x) = I - D f(x).
$$

Since:

$$
D g(x_0) = I - I = 0,
$$

it follows that:

$$
D g(x) \text{ is close to zero}.
$$

Thus, choosing:

$$
\epsilon = \frac{1}{2n},
$$

there exists $\delta > 0$ such that:

$$
\|x - x_0\| < \delta \implies \|D g_x(x)\| \leq \frac{1}{2n}.
$$

Applying the **Contraction Mapping Principle** to $g_x$, we obtain:

$$
\exists x \in B_{\delta}(x_0) \text{ such that } g_x(x) = x.
$$

Thus:

$$
g_x(x) = g_x(x_0) + D g_x(\xi)(x - x_0),
$$

which shows:

$$
D g_x(\xi) (x - x_0).
$$

---
# Chapter 7: Inverse and Implicit Function Theorems

## Contraction Mapping Principle (CMP)  
Let $\mathbb{X}$ be a **complete metric space**, and let $\varphi: \mathbb{X} \to \mathbb{X}$ satisfy:  

$$
d(\varphi(x), \varphi(y)) \leq k \cdot d(x,y), \quad 0 < k < 1.
$$  

Then, there exists a **unique fixed point** $X^*$ such that $\varphi(X^*) = X^*$.

---

## Proof of the Inverse Function Theorem (IFT)  

### Step 1: Reduction  
Assume $Df(x_0) = I$. Define $\tilde{f} = Df(x_0)^{-1} \circ f$, ensuring $D\tilde{f}(x_0) = I$.  
For $x_0 = f^{-1}(y_0)$, define $h(x) = f(x) - f(x_0)$. Since $Dh(x_0) = 0$, solving $f(x) = y$ reduces to:  

$$
x = x_0 - h^{-1}(y - f(x_0)).
$$  

---

### Step 2: Existence of the Inverse**  
Set up: $x_0 = 0, y_0 = f(x_0) = 0, Df(x_0) = I$. Need to show a local inverse:  

$$
\forall y \in W, \quad \exists! x \in U \text{ such that } y = f(x).
$$  

Define:  

$$
g_x(y) = y + x - f(x).
$$  

We need to show $g_x$ has a **unique fixed point**.  

Let $g(x) = x - f(x)$, then $Dg(x) = I - Df(x)$. Since $Dg(x_0) = 0$, choosing $\epsilon = \frac{1}{2n}$ ensures $\|D g_x(x)\|$ is small. Applying **CMP**, we get:  

$$
\exists x \in B_{\delta}(x_0) \text{ such that } g_x(x) = x.
$$
Thus, the inverse exists and is unique.  

# 7.1* Implicit Function Theorem (IFT) Proof

## 1. Recall IFT

**Theorem 7.1.1:** Let $y = f(x): A \subset \mathbb{R}^n \to \mathbb{R}^n$ be of class $C^1$. Suppose $x_0 \in A$ with:
$$
J_f(x_0) = \det(Df(x_0)) \ne 0
$$
Then there exist neighborhoods $U$ of $x_0$ in $A$ and $W$ of $y_0 = f(x_0)$ such that:

1. $f(U) = W$ and $f: U \to W$ has an inverse $f^{-1}: W \to U$.
2. $f^{-1} \in C^1$ (If $f \in C^r$, then $f^{-1} \in C^r$).
3. $Df^{-1}(y) = [Df(x)]^{-1}$ for $x \in U$ and $y = f(x)$.

## 2. Proof of Theorem 7.1.1

### Step 1: Reduction
We may assume $Df(x_0) = I$ and $x_0 = 0$, $y_0 = f(x_0)$.

### Step 2: Existence of inverse
Consider the function $g(x) = x - f(x)$.

- Using continuity of $Dg(x)$ at $0$ and Mean Value Theorem, one can show there exists $\delta > 0$ such that for $x \in B(0, \delta)$:
$$
\|g(x)\| \le \frac{\delta}{2}
$$
- Define $g: B(0, \delta) \to B(0, \frac{\delta}{2})$.
- Let $W = B(0, \frac{\delta}{2})$, and define:
$$
U = \{ x \in B(0, \delta): f(x) \in W \}
$$

### Step 3: Existence of $f^{-1}: W \to U$

Fix $y \in W$. Apply the Contraction Mapping Principle (CMP) to:
$$
g_y(x) = y + x - f(x) = y + g(x)
$$
Then $g_y(x): B(0, \delta) \to B(0, \delta)$. Thus, there exists a unique $x \in B(0, \delta)$ such that:
$$
g_y(x) = x \quad \Longrightarrow \quad f(x) = y
$$
Therefore, $\exists! x \in U$ such that $f(x) = y$.

Fix $y, y_1, y_2 \in W$, let $x_i = f^{-1}(y_i), i = 1,2$. Then:
$$
\| f^{-1}(y_1) - f^{-1}(y_2) \| = \| x_1 - x_2 \|
= \| g_{y_1}(x_1) - g_{y_2}(x_2) \|
$$

Since $\| Dg(x) \| \le \frac{1}{2}$ for $x \in B(0, \delta)$, we get:
$$
\| x_1 - x_2 \| \le 2 \| y_1 - y_2 \|
$$

Thus, $f^{-1}$ is Lipschitz continuous.


### Step 4: Differentiability of $f^{-1}$

(i) **Observation:** $[Df(x_0)]^{-1}$ exists and $Df(x)$ is continuous at $x_0$.

$$ \Rightarrow \exists \delta > 0 \text{ such that } [Df(x)]^{-1} \text{ exists and bounded by } M \text{, } \forall \|x\| \leq \delta $$
$$ \| [Df(x)]^{-1} \| \leq M, \quad \forall x \in B(0, \delta) $$

(ii) Show $f^{-1}$ is differentiable at any $y_* \in W$ and:
$$
Df^{-1}(y_0) = [Df(x_0)]^{-1}, \quad \text{where} \quad y_0 = f(x_0)
$$

Fix $y_* \in W$. Then:
$$
\frac{\| f^{-1}(y) - f^{-1}(y_*) - [Df(x_0)]^{-1}(y - y_*) \|}{\| y - y_* \|}
$$
can be simplified, and as $y \to y_*$, it tends to $0$.

Thus, in conclusion, $f^{-1}(y)$ is differentiable at $y_* \in W$ and:
$$
Df^{-1}(y_*) = [Df(x_*)]^{-1}
$$

---

### Example:

Investigate the invertibility (both local and global) for the map:
$$f \in C^\infty, \quad A = \mathbb{R}^2$$

$$W = (u,v) = f(x,y): \mathbb{R}^2 \to \mathbb{R}^2$$
Given by:
$$
u = e^x\cos y, \quad v = e^x\sin y$$

- Compute Jacobian determinant:
$$
J_f(x,y) = \det(Df(x,y)) =
\begin{vmatrix}
e^x\cos y & -e^x\sin y \\\\
e^x\sin y & e^x\cos y
\end{vmatrix}
= e^{2x} > 0
$$

Thus, by IFT, $f$ is invertible locally at any point and:
$$
Df^{-1}(u,v) = [Df(x,y)]^{-1} =
\begin{bmatrix}
e^x\cos y & -e^x\sin y \\\\
e^x\sin y & e^x\cos y
\end{bmatrix}^{-1}
= \begin{bmatrix}
e^{-x}\cos y & e^{-x}\sin y \\\\
-e^{-x}\sin y & e^{-x}\cos y
\end{bmatrix}
$$

However, $f$ is **not globally invertible** (not injective). Consider:
$$
\begin{aligned}
f(x_0, y_0 + 2\pi) &= (e^{x_0}\cos(y_0 + 2\pi), e^{x_0}\sin(y_0 + 2\pi))\\\\
&= (e^{x_0}\cos y_0, e^{x_0}\sin y_0)\\\\
&= (u_0, v_0)
\end{aligned}
$$

In complex notation, $f$ can be written as:
$$
f(z) = e^z = e^{x+iy} = e^x e^{iy} = e^x(\cos y + i \sin y)
$$
with $u = e^x \cos y$, $v = e^x \sin y$.

---

## Conclusion
Since $f(x, y)$ maps points periodically in $y$, it is not globally injective, despite being locally invertible.

---

## Additional Notes
The periodic nature is reflected in the mapping:
$$f(x_0, y_0 + 2\pi) = f(x_0, y_0)$$
This demonstrates that multiple points in the domain map to the same point in the range, confirming non-injectivity.








